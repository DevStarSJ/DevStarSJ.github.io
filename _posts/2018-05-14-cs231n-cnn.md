---
layout: post
title: "CS231n 5강. Convolutional Neural Networks"
subtitle: "Stanford CS231n Lecture 5. Convolutional Neural Networks"
categories: data
tags: cs231
comments: true
---
Stanfoard [CS231n 2017](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=0)를 요약한 포스팅입니다. 정보 전달보다 자신을 위한 정리 목적이 강한 글입니다! :)


## Convolutional Neural Networks
### History
- 1957, Perceptron
- 1960, Adaline, Madaline
- 1986, First time back-propgation became popular
- 2006, Reinvigorated(활력을 되찾은) research in Deep Learning
- 2012, Imagenet clssification with deep convolutional neural networks

<img src="https://www.dropbox.com/s/fcar9yv3ttkhkvf/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2016.13.26.png?raw=1">

- Hubel & Wiesel의 실험
	- Visual Cortex가 어떻게 동작하는지 밝혀내려고 했습니다
	- 고양이 머리에 전극을 부착하소 서로 다른 시각적 자극을 주었을 때 어떻게 반응하는지 관찰합니다
	- 찾아낸 결론
		- 1. 하나의 영상(시야)엔 Visual Cortext 내의 여러 세포들이 각자 부분을 담당해 인지합니다
		- 중요한 Region은 붉은 색 세포에, 덜 중요하고 주변적인 Region은 파란색 세포에 매핑
		- 2. 인지 과정이 계층적으로 일어납니다(Hierarchical organization)

<img src="https://www.dropbox.com/s/8nakx7sf9xxu7il/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2016.23.35.png?raw=1">

<img src="https://www.dropbox.com/s/13bfjytipg3z9ia/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2016.23.48.png?raw=1">

<img src="https://www.dropbox.com/s/zryr9bkt9vwzg94/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2016.41.45.png?raw=1">

- Neurocognition
	- Hubel & Wiesel의 실험에 영감을 받아 Simple cell과 Complex cell의 구조를 본떠서 만들었습니다
	- 하지만 Backpropagation 방법론 등장 전..!

<img src="https://www.dropbox.com/s/s6jzkvl661g6dtr/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2017.14.53.png?raw=1">

- 최초로 CNN 구조를 Backpropgation을 사용해 학습!
- zip code
- 그러나 데이터가 단순하고 스케일이 작음
 
 
<img src="https://www.dropbox.com/s/4y70aohhzf4lmww/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2017.16.08.png?raw=1">

- AlexNet
	- 1000개의 클래스를 분류하는 ImageNet 대회에서 CNN 모델로는 최초로 1등!!
	- LeNet에 비해 Larger & Deeper
	- 데이터의 양에 비례해 Scalable하며 GPU를 이용한 병렬 연산

## Convolutional Neural Networks
- 제가 작성했던 [Introduction Convolution](https://zzsza.github.io/data/2018/02/23/introduction-convolution/)도 꽤 도움이 됩니다!

### Fully Connected Layer
<img src="https://www.dropbox.com/s/1qhomwxzgngf9ha/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2017.40.32.png?raw=1">

<img src="https://www.dropbox.com/s/rfwlmve8l2b7elp/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2017.42.31.png?raw=1">

- Fully Connected Layer는 이전 Layer의 모든 노드와 연결되어 있습니다. 따라서 Spatial Structure(공간적 구조)를 보존하기에 좋은 구조는 아닙니다

### Convolution Layer
<img src="https://www.dropbox.com/s/ekyailbzq4i97zq/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2017.43.15.png?raw=1">

- Spatial Structure(공간적 구조)를 보존해줍니다
- 작은 필터로 이미지를 슬라이드하며 dot product를 실행합니다

<img src="https://www.dropbox.com/s/vzc4hlt5ttffkg7/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2018.13.22.png?raw=1">

- Filter가 슬라이딩한 것의 결과 : Acitvation Map 

<img src="https://www.dropbox.com/s/hc6e7omiwjrzg7y/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2018.15.53.png?raw=1">

- Convolution Network는 **a sequence of Convolutional Layers, interspersed with activation functions**

<img src="https://www.dropbox.com/s/tx83g1n3ye7dmlz/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2019.37.28.png?raw=1">

- 각 레이어의 Activation map들을 시각화해보니 Heirarchical하게 Feature를 추출하고 있습니다


### A Closer look at spatial dimensions
<img src="https://www.dropbox.com/s/0amecwrdvuhltcd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2019.58.25.png?raw=1">

<img src="https://www.dropbox.com/s/05bqdwq5nrzt08i/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2019.58.43.png?raw=1">

- Q) Stride를 3을 주면 output의 size는 얼마나 될까?
- A) Doesn't fit! : cannot apply 3x3 filter on 7x7 input with stride 3

<img src="https://www.dropbox.com/s/boizp8gnbw55ewq/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.00.03.png?raw=1">

- Output size : (N-F) / stride + 1


### Zero Padding
<img src="https://www.dropbox.com/s/fpmoa3f1u2apcym/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.09.10.png?raw=1">

- output의 size는 7x7!
- zero padding을 1 추가하면 3x3 filter 사용 가능!
- zero padding = (F-1)/2
	- F = 3 => zero pad with 1
	- F = 5 => zero pad with 2
	- F = 7 => zero pad with 3
- 사용하는 이유
	- 1) 원본 이미지 사이즈를 유지하기 위해
	- 2) 가장자리 데이터를 사용하기 위해

### Examples 
<img src="https://www.dropbox.com/s/clcgnlohcw9xlsd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.28.32.png?raw=1">


<img src="https://www.dropbox.com/s/0tq1uwcuwibqfwq/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.30.06.png?raw=1"> 


<img src="https://www.dropbox.com/s/adven4ofizgfzkd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.30.27.png?raw=1">

<img src="https://www.dropbox.com/s/5zmrry8i1sxizq2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.31.00.png?raw=1">

### Convolution Layer Summary
<img src="https://www.dropbox.com/s/ozrjs8aitz0uprz/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.31.36.png?raw=1">

### 1x1 Convolution
<img src="https://www.dropbox.com/s/3e7pai06d1wh1bd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2020.36.20.png?raw=1">

- Filter의 갯수에 따라 output의 dimension(depth)은 달라지지만, 기존 이미지 가로 세로의 사이즈는 그대로 유지됩니다
- Filter의 갯수를 input의 dimension보다 작게하면, dimension reduction의 효과가 납니다
- Image에서 Convolution layer는 Spatial Relation을 고려했다면, 1x1 Convolution layer는 한 픽셀만 고려하기 때문에 dimension reduction(차원 축소) 역할을 위해 사용합니다


## The brain/neuron view of CONV layer
<img src="https://www.dropbox.com/s/gwens9l4ujrv5u9/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2021.10.45.png?raw=1">

- 차이점 : local connectivity
	- entire input 대신 local region만 봄(모든 뉴런들을 연결하는 것이 비실용적이기 때문)
	- Spatial structure를 보존
- Activtion map is 28x28 sheet of neuron outputs
	- Each is connected to a small region in the input
	- All of them share parameters 
- "5x5 filter" => "5x5 receptive field for each neuron"

<img src="https://www.dropbox.com/s/5osdy991t1quczx/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2021.17.55.png?raw=1">

### Pooling layer
- Activation map마다 독립적으로 크기를 downsampling
- 특정 부분의 주변값을 대표하는 하나의 값을 뽑습니다
- Output dimension이 작아지며 Parameter수를 줄입니다
- 그 결과 더 작고 다루기 쉽게 만들 수 있습니다

### MAX Pooling
<img src="https://www.dropbox.com/s/82arxqqa94zq982/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-05-13%2021.23.15.png?raw=1">

- (2x2 filter를 사용하는 경우) 전체 데이터의 75%를 버리고 25%만 선택
	- Computational Complexity 감소
- Filter 내에서 가장 큰 값을 선택
	- Average Pooling은 평균값을 선택. Spatial Structure를 보존하되 이미지가 smooth해짐. Max Pooling은 더 강한 특징만 남기는 방식
- Depth를 줄이지 않고 Spatially하게만 줄임(Height & Width)

- Q) stride와 pooling 모두 downsampling인데 어떤 것을 사용해야 하나요?
- A) 최근 CNN 아키텍쳐는 stride를 사용하는 편이 많습니다. stride 추천합니다

- 힌튼 교수님이 추후에 캡슐넷에서 맥스 풀링의 단점을 이야기했었음! check

### Fully Connected Layer (FC layer)
- Contains neurons that connect to the entire input volume, as in ordinary Neural Networks

## Summary
- ConvNets stack CONV, POOL, FC layers
- Trend towards smaller filters and deeper architectures
- Trend towards getting rid of POOL/FC layers (just CONV) 
- Typical architectures look lik [(CONV-RELU)\*N-POOL?]\*M-(FC-RELU)\*K,SOFTMAX 
	- WHERE N is usually up to ~5, M is large, 0<=k<=2
	- but recent advanced such as ResNet/GoogLeNet challenge this paradigm 



## Reference
- [Stanfoard CS231n 2017](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=0)
